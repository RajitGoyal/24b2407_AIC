{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q2: Transfer Learning for Fashion-MNIST\n",
        "\n",
        "we adapted a pretrained ResNet50 model to classify Fashion-MNIST grayscale images into 10 categories using transfer learning:\n",
        "- Prepared a data pipeline (resize, convert grayscale to RGB)\n",
        "- Build and train a model with a frozen backbone and a new classification head\n",
        "- Fine-tune deeper layers with a lower learning rate\n",
        "- Experimented with data augmentation, learning rate scheduling, and regularization\n"
      ],
      "metadata": {
        "id": "z1iJ-7G8BqZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load Fashion-MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Data augmentation pipeline\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "def create_dataset(images, labels, batch_size=32, augment=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    def preprocess(x, y):\n",
        "        x = tf.image.resize(x[..., tf.newaxis], (224, 224))\n",
        "        x = tf.repeat(x, 3, axis=-1)\n",
        "        if augment:\n",
        "            x = data_augmentation(x)\n",
        "        return x / 255.0, y\n",
        "    return ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "batch_size = 32\n",
        "train_ds = create_dataset(x_train, y_train, batch_size, augment=True)\n",
        "val_ds = create_dataset(x_test, y_test, batch_size)\n"
      ],
      "metadata": {
        "id": "F9KOJXdqB2k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Loading and Preprocessing\n",
        "\n",
        "We load the Fashion-MNIST dataset, resize images to 224x224, convert grayscale to 3-channel RGB, and normalize pixel values. Data augmentation is included for improved generalization.\n"
      ],
      "metadata": {
        "id": "TOo09wJ8CAEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import models\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "cR7617TiCDef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Model Construction\n",
        "\n",
        "We use ResNet50 pretrained on ImageNet as the backbone (without top layers). The backbone is frozen, and a new classification head is added for Fashion-MNIST's 10 classes.\n"
      ],
      "metadata": {
        "id": "gGvqWg_9CGdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_head = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds\n",
        ")\n"
      ],
      "metadata": {
        "id": "_tMoPDS5CJ5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training the Classification Head\n",
        "\n",
        "We train only the new head while keeping the backbone frozen. Mixed precision training is enabled for efficiency. Validation accuracy is recorded after each epoch.\n"
      ],
      "metadata": {
        "id": "lDo6uBEGCWBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-16]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_full = model.fit(\n",
        "    train_ds,\n",
        "    epochs=5,\n",
        "    validation_data=val_ds\n",
        ")\n"
      ],
      "metadata": {
        "id": "OHyAUe1VCaIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fine-Tuning the Backbone\n",
        "\n",
        "We unfreeze the last 16 layers of ResNet50 and continue training with a lower learning rate to adapt higher-level features to Fashion-MNIST.\n"
      ],
      "metadata": {
        "id": "Hii-OC8HCc9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(val_ds)\n",
        "print(f\"Final Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_head.history['val_accuracy'], label='Head Training')\n",
        "plt.plot(range(len(history_head.history['val_accuracy']),\n",
        "         len(history_head.history['val_accuracy']) + len(history_full.history['val_accuracy'])),\n",
        "         history_full.history['val_accuracy'], label='Fine-Tuning')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_head.history['val_loss'], label='Head Training')\n",
        "plt.plot(range(len(history_head.history['val_loss']),\n",
        "         len(history_head.history['val_loss']) + len(history_full.history['val_loss'])),\n",
        "         history_full.history['val_loss'], label='Fine-Tuning')\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m4Ud-GtHCfAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluation and Visualization\n",
        "\n",
        "We evaluate the final model on the test set and plot validation accuracy and loss curves for both training phases.\n"
      ],
      "metadata": {
        "id": "_8z345h4Cho2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Conclusion\n",
        "\n",
        "We successfully adapted a pretrained ResNet50 model to classify Fashion-MNIST images using transfer learning. The approach included data augmentation, learning rate scheduling, regularization, and fine-tuning, resulting in improved validation accuracy.\n"
      ],
      "metadata": {
        "id": "oiLtuUc-CtbX"
      }
    }
  ]
}